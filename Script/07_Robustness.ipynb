{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6bd260-c672-4df6-97bc-25c1f4ec8f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/carmine-\n",
      "[nltk_data]     landolfi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f866ae-a5c0-4c88-9b23-8f52138a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/cleaned_dataset.csv\",encoding='utf-8')\n",
    "\n",
    "p = df.groupby(\"primary_category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2709fa5e-2452-4f12-a3e6-a9a1adf0e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RobustnessConfig:\n",
    "    \"\"\"Configuration loaded from YAML for model and tokenizer.\"\"\"\n",
    "     \n",
    "    data_path: str\n",
    "    model_path: str\n",
    "    tokenizer_name: str\n",
    "    name_model: str\n",
    "    k_per_class: int\n",
    "    min_sent_len: int\n",
    "    n_sentences_per_insert: int\n",
    "    max_length: int\n",
    "    results_csv: str\n",
    "    batch_size: int\n",
    "    data_target_path: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8f5f48-19d5-4da9-9dc6-346698ab8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencePoolBuilder:\n",
    "    \"\"\"\n",
    "    Build a per-class sentence pool from a labeled dataframe using TF-IDF ranking.\n",
    "\n",
    "    The pool is used to contaminate other datasets by sampling representative sentences\n",
    "    from different classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_source : pd.DataFrame\n",
    "        Source dataframe used to extract sentences (this is your in-memory `df`).\n",
    "    text_col : str\n",
    "        Column name containing texts (e.g., \"abstract_clean\").\n",
    "    label_col : str\n",
    "        Column name containing labels (e.g., \"primary_category\").\n",
    "    k_per_class : int\n",
    "        Number of top-ranked sentences (by TF-IDF) to keep per class.\n",
    "    min_sent_len : int\n",
    "        Minimum sentence length (in characters) to consider.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_source: pd.DataFrame,\n",
    "        text_col: str,\n",
    "        label_col: str,\n",
    "        k_per_class: int = 200,\n",
    "        min_sent_len: int = 20,\n",
    "    ) -> None:\n",
    "        self.df_source = df_source\n",
    "        self.text_col = text_col\n",
    "        self.label_col = label_col\n",
    "        self.k_per_class = k_per_class\n",
    "        self.min_sent_len = min_sent_len\n",
    "\n",
    "    def _split_sentences(self, text: str) -> List[str]:\n",
    "        \"\"\"Split a text into sentences and filter very short ones.\"\"\"\n",
    "        if not isinstance(text, str):  # puoi rimuovere\n",
    "            return []\n",
    "        sents = [s.strip() for s in sent_tokenize(text) if isinstance(s, str)]\n",
    "        return [s for s in sents if len(s) >= self.min_sent_len]\n",
    "\n",
    "    def build_pool(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Build the sentence pool using TF-IDF ranking computed across all sentences.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, List[str]]\n",
    "            Mapping: class_label -> list of top-k sentences.\n",
    "        \"\"\"\n",
    "        # Collect sentences with their class\n",
    "        all_sentences: List[str] = []\n",
    "        sent_labels: List[str] = []\n",
    "\n",
    "        grouped = self.df_source.groupby(self.label_col)\n",
    "        per_class_sentences: Dict[str, List[str]] = {}\n",
    "\n",
    "        for label, group in grouped:\n",
    "            sents_label: List[str] = []\n",
    "            for text in group[self.text_col].tolist():\n",
    "                sents = self._split_sentences(text)\n",
    "                sents_label.extend(sents)\n",
    "                \n",
    "            # Deduplicate sentences within class\n",
    "            sents_label = list(dict.fromkeys(sents_label))\n",
    "            per_class_sentences[label] = sents_label\n",
    "            all_sentences.extend(sents_label)\n",
    "            sent_labels.extend([label] * len(sents_label))\n",
    "\n",
    "\n",
    "        # if no sentences, return empty pools\n",
    "        if not all_sentences:\n",
    "            return {c: [] for c in per_class_sentences.keys()}\n",
    "\n",
    "        # TF-IDF over all sentences\n",
    "        tfidf = TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_df=0.9,\n",
    "            min_df=2,\n",
    "            max_features=50000,\n",
    "        )\n",
    "        X = tfidf.fit_transform(all_sentences)\n",
    "\n",
    "        # Sentence score: mean TF-IDF weight (simple, effective)\n",
    "        scores = np.asarray(X.mean(axis=1)).ravel()\n",
    "\n",
    "        # Rank sentences per class by their score\n",
    "        pool: Dict[str, List[str]] = {}\n",
    "        # Build index per class\n",
    "        class_indices: Dict[str, List[int]] = {}\n",
    "        for idx, lab in enumerate(sent_labels):\n",
    "            class_indices.setdefault(lab, []).append(idx)\n",
    "\n",
    "        \n",
    "\n",
    "        for lab, idxs in class_indices.items():\n",
    "            # Sort class sentences by score desc\n",
    "            sorted_local = sorted(idxs, key=lambda i: scores[i], reverse=True)\n",
    "            top_idxs = sorted_local[: self.k_per_class]\n",
    "            top_sents = [all_sentences[i] for i in top_idxs]\n",
    "            pool[lab] = top_sents\n",
    "\n",
    "        return pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6778f0a7-4f99-4ae8-9162-02b1c258f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractContaminator:\n",
    "    \"\"\"\n",
    "    Contaminate a target dataframe by inserting sentences from other classes.\n",
    "\n",
    "    The contamination is applied to a fraction alpha of rows (uniformly sampled).\n",
    "    For each contaminated row, we choose one *different* class at random and insert\n",
    "    `n_sentences` sampled sentences from that class at the end of a randomly chosen\n",
    "    sentence within the abstract (not necessarily at the very end).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_target : pd.DataFrame\n",
    "        The dataframe to contaminate (this is the CSV at ../Datasets/dataset_remaining.csv).\n",
    "    text_col : str\n",
    "        Text column name in df_target (e.g., \"abstract_clean\").\n",
    "    label_col : str\n",
    "        Label column name in df_target (e.g., \"primary_category\").\n",
    "    pool : Dict[str, List[str]]\n",
    "        The sentence pool built from the source df.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_target: pd.DataFrame,\n",
    "        text_col: str,\n",
    "        label_col: str,\n",
    "        pool: Dict[str, List[str]],\n",
    "    ) -> None:\n",
    "        self.df_target = df_target.copy()\n",
    "        self.text_col = text_col\n",
    "        self.label_col = label_col\n",
    "        self.pool = pool\n",
    "        self.rng = random.Random(42)\n",
    "\n",
    "    def _insert_sentences_into_text(self, text: str, contam_sents: List[str]) -> str:\n",
    "        \"\"\"Insert contamination at the end of one random sentence within the text.\"\"\"\n",
    "        sents = [s.strip() for s in sent_tokenize(text)]\n",
    "        if not sents:\n",
    "            # If tokenization fails, just append at the end\n",
    "            return (text or \"\") + \" \" + \" \".join(contam_sents)\n",
    "\n",
    "        insert_idx = self.rng.randrange(0, len(sents))\n",
    "        sents[insert_idx] = (sents[insert_idx].rstrip() + \" \" + \" \".join(contam_sents)).strip()\n",
    "        return \" \".join(sents)\n",
    "\n",
    "    def contaminate(self, alpha: float, n_sentences: int = 2) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply contamination to a fraction alpha of rows (0 < alpha <= 1).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha : float\n",
    "            Fraction of rows to contaminate.\n",
    "        n_sentences : int\n",
    "            Number of sentences to insert from a different class.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A copy of the dataframe with contaminated texts in the same `text_col`.\n",
    "            Adds a boolean column 'contaminated'.\n",
    "        \"\"\"\n",
    "        df_out = self.df_target.copy()\n",
    "        df_out[\"contaminated\"] = False\n",
    "\n",
    "        n = len(df_out)\n",
    "        k = max(1, int(round(alpha * n)))\n",
    "        candidate_indices = list(range(n))\n",
    "        self.rng.shuffle(candidate_indices)\n",
    "        to_contam = set(candidate_indices[:k])\n",
    "\n",
    "        labels_available = [lab for lab, sents in self.pool.items() if len(sents) > 0]\n",
    "        label_set = set(labels_available)\n",
    "\n",
    "        for idx, row in df_out.iterrows():\n",
    "            if idx not in to_contam:\n",
    "                continue\n",
    "\n",
    "            cur_label = row[self.label_col]\n",
    "            # Choose a different label that has sentences\n",
    "            choices = list(label_set - {cur_label})\n",
    "            if not choices:\n",
    "                # No valid contamination class available\n",
    "                continue\n",
    "            chosen_label = self.rng.choice(choices)\n",
    "            source_sents = self.pool.get(chosen_label, [])\n",
    "\n",
    "            if len(source_sents) == 0:\n",
    "                continue\n",
    "\n",
    "            k_sents = min(n_sentences, len(source_sents))\n",
    "            contam_sents = self.rng.sample(source_sents, k_sents)\n",
    "\n",
    "            text = row[self.text_col]\n",
    "            if not isinstance(text, str) or not text.strip():\n",
    "                # Skip if text is empty\n",
    "                continue\n",
    "\n",
    "            new_text = self._insert_sentences_into_text(text, contam_sents)\n",
    "            df_out.at[idx, self.text_col] = new_text\n",
    "            df_out.at[idx, \"contaminated\"] = True\n",
    "\n",
    "        return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd76d47-78ce-456b-9626-abe065b9bee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimpleTextDataset(Dataset):\n",
    "    \"\"\"Torch dataset for batched encoding/prediction.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: Optional[List[int]] = None,\n",
    "        tokenizer=None,\n",
    "        max_length: int = 300,\n",
    "    ) -> None:\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Load a fine-tuned HF model + tokenizer, run predictions, and compute metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Path to the fine-tuned model (HF format, directory with config + weights).\n",
    "    tokenizer_name : str\n",
    "        Name or path of the tokenizer to use.\n",
    "    device : Optional[str]\n",
    "        'cuda' or 'cpu'. If None, auto-detect.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, tokenizer_name: str, device: Optional[str] = None) -> None:\n",
    "        \n",
    "\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)\n",
    "\n",
    "        # Try to get label2id from model config (preferable to match training)\n",
    "        self.label2id: Dict[str, int] = getattr(self.model.config, \"label2id\", {}) or {}\n",
    "        self.id2label: Dict[int, str] = getattr(self.model.config, \"id2label\", {}) or {}\n",
    "        # Normalize possible stringified integers\n",
    "        self.label2id = {str(k): int(v) for k, v in self.label2id.items()} if self.label2id else {}\n",
    "\n",
    "    def _encode_labels(\n",
    "        self, labels_str: List[str], strict: bool = True\n",
    "    ) -> Tuple[List[int], Dict[str, int]]:\n",
    "        \"\"\"\n",
    "        Map string labels to ids, using model config if available; else build a mapping.\n",
    "\n",
    "        If `strict=True` and some labels are missing in the model mapping, raise ValueError.\n",
    "        \"\"\"\n",
    "        if self.label2id:\n",
    "            missing = [l for l in set(labels_str) if str(l) not in self.label2id]\n",
    "            if missing and strict:\n",
    "                raise ValueError(\n",
    "                    f\"Found labels not present in model config label2id: {missing}. \"\n",
    "                    f\"Please ensure your evaluation set uses the same label space as training.\"\n",
    "                )\n",
    "            # Map known labels\n",
    "            label2id_eff = self.label2id.copy()\n",
    "            # Fallback for any stray label\n",
    "            next_id = max(label2id_eff.values()) + 1 if label2id_eff else 0\n",
    "            for l in set(labels_str):\n",
    "                if str(l) not in label2id_eff:\n",
    "                    label2id_eff[str(l)] = next_id\n",
    "                    next_id += 1\n",
    "        else:\n",
    "            # Build a mapping from the dataset (sorted for determinism)\n",
    "            uniq = sorted(set(labels_str))\n",
    "            label2id_eff = {str(l): i for i, l in enumerate(uniq)}\n",
    "\n",
    "        y = [label2id_eff[str(l)] for l in labels_str]\n",
    "        return y, label2id_eff\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        text_col: str,\n",
    "        label_col: str,\n",
    "        batch_size: int = 16,\n",
    "        max_length: int = 512,\n",
    "        strict_labels: bool = True,\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Tokenize, predict and compute loss/accuracy/f1/precision/recall.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, float]\n",
    "        \"\"\"\n",
    "        texts = df[text_col].astype(str).tolist()\n",
    "        labels_str = df[label_col].astype(str).tolist()\n",
    "        y_true, _ = self._encode_labels(labels_str, strict=strict_labels)\n",
    "\n",
    "        dataset = SimpleTextDataset(texts, y_true, tokenizer=self.tokenizer, max_length=max_length)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        self.model.eval()\n",
    "        loss_fn = CrossEntropyLoss()\n",
    "        total_loss = 0.0\n",
    "        n_examples = 0\n",
    "        preds_all: List[int] = []\n",
    "        trues_all: List[int] = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, labels)\n",
    "\n",
    "                total_loss += loss.item() * labels.size(0)\n",
    "                n_examples += labels.size(0)\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                preds_all.extend(preds.cpu().tolist())\n",
    "                trues_all.extend(labels.cpu().tolist())\n",
    "\n",
    "        avg_loss = total_loss / max(1, n_examples)\n",
    "        acc = accuracy_score(trues_all, preds_all)\n",
    "        f1 = f1_score(trues_all, preds_all, average=\"weighted\")\n",
    "        prec = precision_score(trues_all, preds_all, average=\"weighted\", zero_division=0)\n",
    "        rec = recall_score(trues_all, preds_all, average=\"weighted\")\n",
    "\n",
    "        return {\n",
    "            \"loss\": float(avg_loss),\n",
    "            \"accuracy\": float(acc),\n",
    "            \"f1\": float(f1),\n",
    "            \"precision\": float(prec),\n",
    "            \"recall\": float(rec),\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab36654-40ae-4058-8508-fb903f1b50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../Datasets/robustness_contaminated_results.csv\n",
      "       model  alpha      loss  accuracy        f1  precision    recall\n",
      "0  Bert_base    0.0  1.188087  0.655016  0.647920   0.650607  0.655016\n",
      "1  Bert_base    0.1  1.220143  0.648830  0.641815   0.644697  0.648830\n",
      "2  Bert_base    0.2  1.251844  0.643159  0.636491   0.640023  0.643159\n",
      "3  Bert_base    0.3  1.277091  0.637901  0.630635   0.633700  0.637901\n"
     ]
    }
   ],
   "source": [
    "### Initial parameters\n",
    "Config_yaml_path = \"../File_Yaml/Robustness.yaml\"  \n",
    "Alphas = [0.1, 0.2, 0.3]\n",
    "\n",
    "# 1) Load config\n",
    "with open(Config_yaml_path, \"r\") as f:\n",
    "    cfg_raw = yaml.safe_load(f)\n",
    "    \n",
    "cfg = RobustnessConfig(\n",
    "    data_path = cfg_raw[\"data_path\"],\n",
    "    model_path=cfg_raw[\"model_path\"],\n",
    "    tokenizer_name=cfg_raw[\"tokenizer_name\"],\n",
    "    name_model=cfg_raw[\"name_model\"],\n",
    "    k_per_class = cfg_raw[\"top_k\"],\n",
    "    min_sent_len = cfg_raw[\"min_sent_len\"],\n",
    "    n_sentences_per_insert = cfg_raw[\"n_sentences_at_time\"],\n",
    "    max_length = cfg_raw[\"max_length\"],\n",
    "    results_csv=cfg_raw[\"results_csv\"],\n",
    "    batch_size = cfg_raw[\"batch_size\"],\n",
    "    data_target_path=cfg_raw[\"data_target_path\"],\n",
    ")\n",
    "# load dataet to create a pool of sentences\n",
    "df = pd.read_csv(cfg.data_path, encoding='utf-8')\n",
    "text_col = \"abstract_clean\"\n",
    "label_col = \"primary_category\"\n",
    "\n",
    "# 2) Build TF-IDF sentence pool from the *source* df (already in memory)\n",
    "pool_builder = SentencePoolBuilder(\n",
    "    df_source=df,\n",
    "    text_col= text_col,\n",
    "    label_col= label_col,\n",
    "    k_per_class= cfg.k_per_class,\n",
    ")\n",
    "sentence_pool = pool_builder.build_pool()\n",
    "\n",
    "# 3) Load the target dataset \n",
    "df_target = pd.read_csv(cfg.data_target_path)\n",
    "\n",
    "# Split train/val\n",
    "df_target_train, df_target_val  = train_test_split(\n",
    "      df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4) Prepare contaminator and evaluator\n",
    "contaminator = AbstractContaminator(\n",
    "    df_target= df_target_val,\n",
    "    text_col= text_col,\n",
    "    label_col= label_col,\n",
    "    pool= sentence_pool,\n",
    ")\n",
    "\n",
    "evaluator = ModelEvaluator(model_path=cfg.model_path, tokenizer_name=cfg.tokenizer_name)\n",
    "\n",
    "# 5) Loop over alphas, contaminate, evaluate, collect results\n",
    "results: List[Dict[str, float]] = []\n",
    "\n",
    "# Evaluate also the clean baseline (alpha = 0.0)\n",
    "metrics_clean = evaluator.evaluate(df_target_val, text_col= text_col, label_col= label_col,\n",
    "                                   batch_size= cfg.batch_size, max_length= cfg.max_length)\n",
    "metrics_clean[\"model\"] = cfg.name_model\n",
    "metrics_clean[\"alpha\"] = 0.0\n",
    "results.append(metrics_clean)\n",
    "\n",
    "for alpha in Alphas:\n",
    "    df_cont = contaminator.contaminate(alpha=alpha, n_sentences=cfg.n_sentences_per_insert)\n",
    "    metrics = evaluator.evaluate(df_cont, text_col=text_col, label_col= label_col,\n",
    "                                 batch_size= cfg.batch_size, max_length= cfg.max_length)\n",
    "    metrics[\"model\"] = cfg.name_model\n",
    "    metrics[\"alpha\"] = float(alpha)\n",
    "    results.append(metrics)\n",
    "\n",
    "# 6) Save to CSV (append if exists)\n",
    "os.makedirs(os.path.dirname(cfg.results_csv), exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"alpha\", \"loss\", \"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    ")\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.isfile(cfg.results_csv):\n",
    "    # Create new file with header\n",
    "    results_df.to_csv(cfg.results_csv, index=False)\n",
    "else:\n",
    "    # Append without writing the header again\n",
    "    results_df.to_csv(cfg.results_csv, mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"Results saved to: {cfg.results_csv}\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
